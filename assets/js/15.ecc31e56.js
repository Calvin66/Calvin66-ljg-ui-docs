(window.webpackJsonp=window.webpackJsonp||[]).push([[15],{421:function(v,_,t){"use strict";t.r(_);var r=t(12),d=Object(r.a)({},(function(){var v=this,_=v._self._c;return _("ContentSlotsDistributor",{attrs:{"slot-key":v.$parent.slotKey}},[_("h1",{attrs:{id:"上下游数据一览"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#上下游数据一览"}},[v._v("#")]),v._v(" 上下游数据一览")]),v._v(" "),_("h2",{attrs:{id:"sql-作业的上下游数据介绍"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#sql-作业的上下游数据介绍"}},[v._v("#")]),v._v(" SQL 作业的上下游数据介绍")]),v._v(" "),_("ul",[_("li",[_("p",[v._v("数据源（Source）指的是输入流计算系统的上游数据来源。")])]),v._v(" "),_("li",[_("p",[v._v("数据目的（Sink）指的是流计算系统输出处理结果的目的地。")])]),v._v(" "),_("li",[_("p",[v._v("用户也可以上传自定义的 Connector 程序包，以支持更多的数据源和数据目的。")])])]),v._v(" "),_("table",[_("thead",[_("tr",[_("th",[v._v("上下游")]),v._v(" "),_("th",[v._v("作为流数据源")]),v._v(" "),_("th",[v._v("作为批数据源")]),v._v(" "),_("th",[v._v("作为维表")]),v._v(" "),_("th",[v._v("作为Append数据源")]),v._v(" "),_("th",[v._v("作为Upsert数据源")])])]),v._v(" "),_("tbody",[_("tr",[_("td",[v._v("Kafka")]),v._v(" "),_("td",[v._v("支持")]),v._v(" "),_("td",[v._v("支持（JAR 作业）")]),v._v(" "),_("td",[v._v("-")]),v._v(" "),_("td",[v._v("支持")]),v._v(" "),_("td",[v._v("支持")])]),v._v(" "),_("tr",[_("td",[v._v("Upsert Kafka")]),v._v(" "),_("td",[v._v("支持")]),v._v(" "),_("td",[v._v("支持（JAR 作业）")]),v._v(" "),_("td",[v._v("-")]),v._v(" "),_("td",[v._v("-")]),v._v(" "),_("td",[v._v("支持")])]),v._v(" "),_("tr",[_("td",[v._v("MySQL")]),v._v(" "),_("td",[v._v("-")]),v._v(" "),_("td",[v._v("支持")]),v._v(" "),_("td",[v._v("支持")]),v._v(" "),_("td",[v._v("支持")]),v._v(" "),_("td",[v._v("支持")])]),v._v(" "),_("tr",[_("td",[v._v("Hbase")]),v._v(" "),_("td",[v._v("-")]),v._v(" "),_("td",[v._v("支持")]),v._v(" "),_("td",[v._v("支持")]),v._v(" "),_("td",[v._v("支持")]),v._v(" "),_("td",[v._v("支持")])]),v._v(" "),_("tr",[_("td",[v._v("Hive")]),v._v(" "),_("td"),v._v(" "),_("td",[v._v("支持")]),v._v(" "),_("td",[v._v("支持")]),v._v(" "),_("td",[v._v("支持")]),v._v(" "),_("td",[v._v("-")])]),v._v(" "),_("tr",[_("td",[v._v("StarRocks")]),v._v(" "),_("td",[v._v("-")]),v._v(" "),_("td",[v._v("支持")]),v._v(" "),_("td",[v._v("-")]),v._v(" "),_("td",[v._v("支持")]),v._v(" "),_("td",[v._v("支持")])]),v._v(" "),_("tr",[_("td",[v._v("Elasticsearch")]),v._v(" "),_("td",[v._v("-")]),v._v(" "),_("td",[v._v("-")]),v._v(" "),_("td",[v._v("-")]),v._v(" "),_("td",[v._v("支持")]),v._v(" "),_("td",[v._v("支持")])])])]),v._v(" "),_("h2",{attrs:{id:"jar-作业的上下游数据介绍"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#jar-作业的上下游数据介绍"}},[v._v("#")]),v._v(" JAR 作业的上下游数据介绍")]),v._v(" "),_("p",[v._v("关于 JAR 作业的 Source 和 Sink 的开发和使用方式，可参见 Flink 官方文档的 "),_("a",{attrs:{href:"https://nightlies.apache.org/flink/flink-docs-release-1.14/docs/connectors/datastream/overview/",target:"_blank",rel:"noopener noreferrer"}},[v._v("DataStream Connectors"),_("OutboundLink")],1),v._v("。")])])}),[],!1,null,null,null);_.default=d.exports}}]);